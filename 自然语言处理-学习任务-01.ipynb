{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础理论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "智能音箱、客服机器人、人脸识别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Github 用于存储、管理、共享代码、文档及其版本。\n",
    "- Jupyter 用于科研学习并且可分享代码和笔记文档。\n",
    "- Pycharm 用于软件工程项目开发。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概率模型是指基于统计概率学理论而提出的相关模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 垃圾邮件识别。\n",
    "- 天气预报。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 困难点是自然语言没有统一的规范，难以判断一个语句的合理性。\n",
    "- 使用统计概率模型的原因是为了判断语句合理性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "语言模型也是一种概率模型，但是基于马尔科夫假设，简化了统计计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 句子纠错、单词纠错。\n",
    "- 输入法候选项、搜索提示。\n",
    "- 在随机生成的文本中选择最可能是规范语句的文本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "句子中单词出现的概率和其它单词无关。\n",
    "$$\n",
    "P(sentence)=P(w_1)*P(w_2)*P(w_3)*...*P(w_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 优点：易于计算\n",
    "- 缺点：没有考虑单词出现和上下文的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "句子中单词出现的概率和前面或后面的一个单词有关。\n",
    "$$\n",
    "P(sentence)=P(w_1)*P(w_2|w_1)*P(w_3|w_2)*...*P(w_n|w_{n-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编程实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设计句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_grammar = \"\"\"\n",
    "default => sentence\n",
    "sentence => noun_phrase verb_phrase\n",
    "noun_phrase => Article Adj* noun\n",
    "Adj* => null|Adj Adj*\n",
    "verb_phrase => verb noun_phrase\n",
    "Article => 一个|这个\n",
    "noun => 女人|篮球|桌子|小猫\n",
    "verb => 看着|听着|看见\n",
    "Adj => 蓝色的|好看的|小小的|年轻的\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "thinking_grammar = \"\"\"\n",
    "default => what\n",
    "what => 什么 是 名词\n",
    "名词 =>  机器|思考|智能|语言\n",
    "why_has => 为什么有 名词\n",
    "why_do => 为什么要 动词短语\n",
    "动词短语 => 动词 名词\n",
    "动词 => 听说|发现|产生\n",
    "when => 什么时候 动词短语\n",
    "where => 在哪里 动词短语\n",
    "人名 => 图灵\n",
    "who => 人名 是谁\n",
    "how => 怎么样 动词短语\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用generae函数生成句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一个年轻的桌子看见一个好看的小小的篮球\n",
      "一个年轻的好看的小小的女人\n",
      "听着这个蓝色的桌子\n",
      "篮球\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def __grammar_to_kvs(grammar_str, split_token='=>'):\n",
    "    lines = grammar_str.splitlines()\n",
    "    kvs = {}\n",
    "    for line in lines:\n",
    "        if len(line)!=0:\n",
    "            k=line.split(split_token)[0].strip()\n",
    "            v=line.split(split_token)[1].strip()\n",
    "            kvs[k]=v\n",
    "#     print(kvs)\n",
    "    return kvs\n",
    "\n",
    "def __has_children(key, kvs):\n",
    "    can = False\n",
    "    if key in kvs.keys() and '*' not in key and '|' not in key:\n",
    "        can = True\n",
    "    return can\n",
    "\n",
    "def generate_tree(grammar_str, key):\n",
    "    kvs = __grammar_to_kvs(grammar_str)\n",
    "    value = kvs[key]\n",
    "    if '|'  in value:\n",
    "        value.replace(' ','')\n",
    "    results = value.split(' ')\n",
    "    for i,key in enumerate(results):\n",
    "#         print('key has_childs? key=',key,'has=',__has_children(key, kvs),'i=',i,'k=',key)\n",
    "        if __has_children(key, kvs):\n",
    "            tmp =generate_tree(grammar_str, key)\n",
    "            results[i]=tmp\n",
    "        else:\n",
    "            if '*' in key:\n",
    "                tmp = ''\n",
    "                word_type = key.split('*')[0]\n",
    "                to_choice = kvs[word_type].split('|')\n",
    "                words_count = random.randint(0,len(to_choice)-1) \n",
    "                while words_count>0:\n",
    "                    choice_idx=random.randint(0,len(to_choice)-1)\n",
    "                    choice_word=to_choice[choice_idx]\n",
    "                    to_choice.remove(choice_word)\n",
    "                    tmp+=choice_word\n",
    "                    words_count-=1\n",
    "                results[i]=tmp\n",
    "            elif '|' in key:\n",
    "                key_randoms = key.split('|')\n",
    "#                 map(lambda e:e.strip(), key_randoms)\n",
    "#                 print(key_randoms)\n",
    "                tmp = key_randoms[random.randint(0,len(key_randoms)-1)]\n",
    "                results[i]=tmp\n",
    "\n",
    "    return results\n",
    "\n",
    "def tree_to_string(root):\n",
    "    result = ''\n",
    "    for node in root:\n",
    "        if type(node)==list:\n",
    "            result+=tree_to_string(node)\n",
    "        else:\n",
    "            result+=node\n",
    "    return result\n",
    "\n",
    "def generate(grammar_str, key='default'):\n",
    "    tree = generate_tree(grammar_str, key)\n",
    "    return tree_to_string(tree)\n",
    "\n",
    "print(generate(simple_grammar))\n",
    "print(generate(simple_grammar, 'noun_phrase'))\n",
    "print(generate(simple_grammar, 'verb_phrase'))\n",
    "print(generate(simple_grammar, 'noun'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "怎么样听说机器\n"
     ]
    }
   ],
   "source": [
    "print(generate(thinking_grammar,'how'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 generate_n 拓展 generate，能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一个小猫看见一个好看的女人', '一个蓝色的篮球看见这个年轻的小小的篮球', '这个小小的蓝色的小猫看见这个好看的小猫', '这个女人看着这个年轻的蓝色的小小的女人', '一个好看的年轻的小小的桌子看见这个好看的年轻的桌子', '这个好看的小猫看着一个女人', '这个年轻的好看的蓝色的篮球听着一个蓝色的年轻的小小的桌子', '这个篮球看见这个桌子', '这个女人看着一个蓝色的好看的小小的桌子', '这个女人看见一个小小的好看的小猫']\n"
     ]
    }
   ],
   "source": [
    "def generate_n(n):\n",
    "    results = []\n",
    "    for i in range(n):\n",
    "        s = generate(simple_grammar)\n",
    "        results.append(s)\n",
    "#         print(s)\n",
    "    return results    \n",
    "    \n",
    "s = generate_n(10)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 文本数据集\n",
    "    + 数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "\n",
    "目前模型选用数据集1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.937887932904423e-13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "dataset = []\n",
    "two_gram_dataset = []\n",
    "\n",
    "with open('train.txt', 'r') as file_in:\n",
    "    with open('train_out.txt', 'w') as file_out:\n",
    "        buffer = []\n",
    "        buffer_size = 100\n",
    "        for line in file_in:\n",
    "            ss = re.findall('[\\u4e00-\\u9fa5]*',line)\n",
    "            ss = [s for s in ss if len(s) > 0]\n",
    "            file_out.write('S')\n",
    "            dataset.append('S')\n",
    "            for sentence in ss:\n",
    "                file_out.write(sentence)\n",
    "                file_out.write('E')\n",
    "                items = list(sentence)\n",
    "                for item in items:\n",
    "                    dataset.append(item)\n",
    "                dataset.append('E')\n",
    "# print(dataset[-1])\n",
    "\n",
    "def build_two_gram(dataset, two_gram_dataset):\n",
    "    for i in range(len(dataset)-1):\n",
    "        two_gram_dataset.append(dataset[i]+dataset[i+1])\n",
    "\n",
    "build_two_gram(dataset, two_gram_dataset)\n",
    "\n",
    "# print(two_gram_dataset[-1])\n",
    "\n",
    "def condition_prob(item, item_next, dataset, two_gram_dataset):\n",
    "    count_item = dataset.count(item)\n",
    "    count_two = two_gram_dataset.count(item+item_next)\n",
    "\n",
    "    if count_two == 0 and count_item != 0:\n",
    "        count_two = 1\n",
    "    if count_item == 0:\n",
    "        p = 1/len(dataset)\n",
    "    else:\n",
    "        p = count_two/count_item\n",
    "        \n",
    "#     print(item, item_next, count_item, count_two, p)\n",
    "    return p\n",
    "\n",
    "\n",
    "                \n",
    "def language_model_prob(sentence):\n",
    "    sentence = 'S' + sentence + 'E'\n",
    "    items = list(sentence)\n",
    "    p_sentence = 1\n",
    "    for i in range(len(items)-1):\n",
    "        p_item = condition_prob(items[i], items[i+1], dataset, two_gram_dataset) \n",
    "        p_sentence = p_sentence * p_item\n",
    "    return p_sentence\n",
    "        \n",
    "print(language_model_prob('你好呀'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'一个好看的蓝色的小猫看见一个桌子'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_best(): \n",
    "    sentences = generate_n(10)\n",
    "#     print(sentences)\n",
    "    sentences = sorted(sentences, key=lambda s: language_model_prob(s), reverse=True)\n",
    "#     print(sentences)\n",
    "#     print(language_model_prob(sentences[0]), ',' ,language_model_prob( sentences[-1]))\n",
    "    return sentences[0]\n",
    "\n",
    "generate_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 这个模型存在的问题？如何提升？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这个模型局限于有限的数据集，很可能因为样本的限制导致模型不能准确判断有新单词的句子的规范程度。\n",
    "- 提升方式：\n",
    "  - 扩大数据集。\n",
    "  - 修改产生模型的方式，例如采用神经网络。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
